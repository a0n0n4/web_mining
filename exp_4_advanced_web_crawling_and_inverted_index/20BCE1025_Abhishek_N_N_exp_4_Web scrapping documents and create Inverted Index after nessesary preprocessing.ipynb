{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# import the necessary libraries\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "# remove whitespace from text\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "# remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return ' '.join([token for token in tokens if token not in stopword_list])\n",
    "# stemming\n",
    "def stem_text(text):\n",
    "    ps = nltk.PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return ' '.join([ps.stem(token) for token in tokens])\n",
    "# lemmatization\n",
    "def lemmatize_text(text):\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return ' '.join([wnl.lemmatize(token) for token in tokens])\n",
    "# remove special characters\n",
    "def remove_special_characters(text):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "# remove extra newlines\n",
    "def remove_extra_newlines(text):\n",
    "    pattern=r'[\\r|\\n|\\r]+'\n",
    "    text=re.sub(pattern,' ',text)\n",
    "    return text\n",
    "\n",
    "# apply all the functions to the text\n",
    "def preprocess(corpus):\n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        doc = text_lowercase(doc)\n",
    "        doc = remove_numbers(doc)\n",
    "        doc = remove_punctuation(doc)\n",
    "        doc = remove_whitespace(doc)\n",
    "        doc = remove_special_characters(doc)\n",
    "        doc = remove_extra_newlines(doc)\n",
    "        doc = lemmatize_text(doc)\n",
    "        doc = stem_text(doc)\n",
    "        doc = remove_stopwords(doc)\n",
    "        normalized_corpus.append(doc)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted index\n",
    "def generateInvertedIndexDict(dataFromDoc: list[str]) :\n",
    "    d=dict()\n",
    "\n",
    "    termsListFromDoc = [s.split() for s in dataFromDoc]\n",
    "    \n",
    "    for docId, termList in enumerate(termsListFromDoc):\n",
    "        for term in termList:\n",
    "            if term not in d:\n",
    "                d[term]={docId}\n",
    "            else:\n",
    "                d[term].add(docId)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file handling\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "def getDataFromDocs(dir):\n",
    "    \"\"\"\n",
    "    gets strings from docs \n",
    "\n",
    "    parameters:\n",
    "\n",
    "    dir (str) : directroy which contains all files\n",
    "\n",
    "    return: \n",
    "    list of str read from docs in the directory given by user\n",
    "\n",
    "    \"\"\"\n",
    "    return [open(join(dir, f)).read() for f in sorted(listdir(dir)) if isfile(join(dir, f))]\n",
    "\n",
    "def getDocIDToDocNameMap(dir):\n",
    "    \"\"\"\n",
    "    gets the map of docID to docName\n",
    "\n",
    "    parameters:\n",
    "\n",
    "    dir (str) : directroy which contains all files\n",
    "\n",
    "    return: \n",
    "    dict of docID to docName of docs in the directory given by user\n",
    "\n",
    "    \"\"\"\n",
    "    return {i:x for i, x in enumerate([f for f in sorted(listdir(dir)) if isfile(join(dir, f))])}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/the-winters-tale_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/venus-and-adonis_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/the-two-noble-kinsmen_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/the-two-gentlemen-of-verona_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/twelfth-night_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/troilus-and-cressida_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/titus-andronicus_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/timon-of-athens_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/the-tempest_TXT_FolgerShakespeare.txt\",\n",
    "    \"https://shakespeare.folger.edu/downloads/txt/romeo-and-juliet_TXT_FolgerShakespeare.txt\"\n",
    "      ]\n",
    "l=[]\n",
    "for url in urls:\n",
    "    textPage = urlopen(url)\n",
    "    l.append(textPage.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted index becomes to long so took only first 100 characters\n",
    "for i in range(len(l)):\n",
    "    l[i]=str(l[i])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'The Winter\\\\'s Tale\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n  \",\n",
       " \"b'Venus and Adonis\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n  wi\",\n",
       " \"b'The Two Noble Kinsmen\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\\",\n",
       " \"b'The Two Gentlemen of Verona\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werst\",\n",
       " \"b'Twelfth Night\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n  with \",\n",
       " \"b'Troilus and Cressida\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n\",\n",
       " \"b'Titus Andronicus\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n  wi\",\n",
       " \"b'Timon of Athens\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n  wit\",\n",
       " \"b'The Tempest\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n  with Mi\",\n",
       " \"b'Romeo and Juliet\\\\r\\\\nby William Shakespeare\\\\r\\\\nEdited by Barbara A. Mowat and Paul Werstine\\\\r\\\\n  wi\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bthe winter talernbi william shakespearernedit barbara mowat paul werstinern',\n",
       " 'bvenu adonisrnbi william shakespearernedit barbara mowat paul werstinern wi',\n",
       " 'bthe two nobl kinsmenrnbi william shakespearernedit barbara mowat paul werstin',\n",
       " 'bthe two gentleman veronarnbi william shakespearernedit barbara mowat paul werst',\n",
       " 'btwelfth nightrnbi william shakespearernedit barbara mowat paul werstinern',\n",
       " 'btroilu cressidarnbi william shakespearernedit barbara mowat paul werstinern',\n",
       " 'btitu andronicusrnbi william shakespearernedit barbara mowat paul werstinern wi',\n",
       " 'btimon athensrnbi william shakespearernedit barbara mowat paul werstinern wit',\n",
       " 'bthe tempestrnbi william shakespearernedit barbara mowat paul werstinern mi',\n",
       " 'bromeo julietrnbi william shakespearernedit barbara mowat paul werstinern wi']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_text=preprocess(l)\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bthe': {0, 2, 3, 8},\n",
       " 'winter': {0},\n",
       " 'talernbi': {0},\n",
       " 'william': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       " 'shakespearernedit': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       " 'barbara': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       " 'mowat': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       " 'paul': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       " 'werstinern': {0, 1, 4, 5, 6, 7, 8, 9},\n",
       " 'bvenu': {1},\n",
       " 'adonisrnbi': {1},\n",
       " 'wi': {1, 6, 9},\n",
       " 'two': {2, 3},\n",
       " 'nobl': {2},\n",
       " 'kinsmenrnbi': {2},\n",
       " 'werstin': {2},\n",
       " 'gentleman': {3},\n",
       " 'veronarnbi': {3},\n",
       " 'werst': {3},\n",
       " 'btwelfth': {4},\n",
       " 'nightrnbi': {4},\n",
       " 'btroilu': {5},\n",
       " 'cressidarnbi': {5},\n",
       " 'btitu': {6},\n",
       " 'andronicusrnbi': {6},\n",
       " 'btimon': {7},\n",
       " 'athensrnbi': {7},\n",
       " 'wit': {7},\n",
       " 'tempestrnbi': {8},\n",
       " 'mi': {8},\n",
       " 'bromeo': {9},\n",
       " 'julietrnbi': {9}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateInvertedIndexDict(preprocessed_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'গত বছর অক্টোবরে হাওড়ার অপ্রকাশ মুখার্জি লেনের বাসিন্দা ব্যবসায়ী শৈলে পাণ্ডের বাড়িতে হানা দেয় পুলিশ। দু’দিনের অভিযানে নগদ ৮ কোটি ১৫ লক্ষ টাকা-সহ উদ্ধার হয় সোনা ও হিরের গয়না। '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textPage = urlopen(\"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/bangla_1_.txt\")\n",
    "textPage.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['গত বছর অক্টোবরে হাওড়ার অপ্রকাশ মুখার্জি লেনের বাসিন্দা ব্যবসায়ী শৈলে পাণ্ডের বাড়িতে হানা দেয় পুলিশ। দু’দিনের অভিযানে নগদ ৮ কোটি ১৫ লক্ষ টাকা-সহ উদ্ধার হয় সোনা ও হিরের গয়না। ',\n",
       " 'নাগপুরে অস্ট্রেলিয়ার বিরুদ্ধে টেস্ট শুরুর আগেই বিতর্কে ভারতীয় ক্রিকেট। রাহুল দ্রাবিড় থাকার পরেও সূর্যকুমারকে অভিষেকের টুপি দেন রবি শাস্ত্রী। এই ঘটনা নিয়েই প্রশ্ন উঠছে। ',\n",
       " 'রত্নগিরির পেট্রো রসায়নের অন্দরের খবর এবং এই প্রকল্প ঘিরে যে দুষ্টচক্র গড়ে উঠেছে, তা নিয়ে সোমবার সংবাদপত্রে লিখেছিলেন শশীকান্ত। তার পরই মঙ্গলবার গাড়িচাপা দিয়ে খুন করা হয়। ',\n",
       " \"महाविनाश के बीच तुर्की में 'भूकंप टैक्स' पर आक्रोश, हजारों की मौत के बाद फूटा लोगों का गुस्सा \",\n",
       " 'राहुल के 51 मिनट Vs पीएम मोदी के 88 मिनट, किसके भाषण में कौन से मुद्दे रहे हावी?',\n",
       " 'बॉर्डर-गावस्कर ट्रॉफी कल से...पहला मुकाबला नागपुर में:इंडिया के टॉप ऑर्डर और स्पिनर्स का रोल अहम, वे 5 फैक्टर जो सीरीज का रिजल्ट तय करेंगे',\n",
       " 'ರಾಮಕೃಷ್ಣ ಹೆಗಡೆಯವರಿಗೆ ಕಲ್ಲು ಹೊಡೆದವರು ಯಾರು? ರಕ್ತದಲ್ಲೇ ಬ್ರಾಹ್ಮಣ ವಿರೋಧಿತನ ಇದೆ; 3 ಜಿಲ್ಲೆ ಇಟ್ಟುಕೊಂಡು ಸಿಎಂ ಆಗುವ ಕನಸೇತಕೆ?',\n",
       " 'ಜನವರಿಯಲ್ಲಿ   ಟಾಟಾ ಮೋಟಾರ್ಸ್ 47,987 ಕಾರುಗಳನ್ನು ಮಾರಾಟ ಮಾಡಿದೆ. ವಾರ್ಷಿಕ ಆಧಾರದ ಮೇಲೆ ನೋಡುವುದಾದರೆ ಕಾರಿನ ಮಾರಾಟ 17.68 ಪ್ರತಿಶತದಷ್ಟು ಹೆಚ್ಚಾಗಿದೆ. ಕಳೆದ ವರ್ಷ ಈ ಜನವರಿಯಲ್ಲಿ ಕೇವಲ 40777 ಯೂನಿಟ್\\u200cಗಳಷ್ಟು ಟಾಟಾ ಕಾರು ಮಾರಾಟವಾಗಿತ್ತು. ಆದರೆ, ಜನವರಿ 2023 ರಲ್ಲಿ, ಕಂಪನಿಯು ಇದಕ್ಕಿಂತ 7210 ಹೆಚ್ಚು ಯುನಿಟ್\\u200cಗಳನ್ನು ಕಂಪನಿ ಮಾರಾಟ ಮಾಡಿದೆ. ಇದರೊಂದಿಗೆ, ಟಾಟಾ ಮೋಟಾರ್ಸ್ ದೇಶದ ಮೂರನೇ ಅತಿದೊಡ್ಡ ಕಾರು ಮಾರಾಟ ಕಂಪನಿಯಾಗಿ ಹೊರ ಹೊಮ್ಮಿದೆ. ಕಂಪನಿಯ ಹೆಚ್ಚು ಮಾರಾಟವಾಗುವ ಕಾರುಗಳು ಯಾವುವು ನೋಡೋಣ. ',\n",
       " 'ನವದೆಹಲಿ: ಭೂಕಂಪದಿಂದ ಜರ್ಝರಿತವಾಗಿರುವ ಟರ್ಕಿ ಮತ್ತು ಸಿರಿಯಾ (Turkey and Syria Earthquake) ದೇಶಗಳಿಗೆ ಜಗತ್ತಿನ ಅನೇಕ ದೇಶಗಳು ಸಹಾಯಹಸ್ತ ಚಾಚಿವೆ. ಭಾರತ ಕೂಡ ವಿವಿಧ ರಕ್ಷಣಾ ಸಾಮಗ್ರಿಗಳನ್ನು (India Rescue Team To Turkey) ಟರ್ಕಿಗೆ ಕಳುಹಿಸಿಕೊಟ್ಟಿದೆ. ಔಷಧಿ, ರಕ್ಷಣಾ ಸಿಬ್ಬಂದಿ, ಶ್ವಾನ ದಳ ಇತ್ಯಾದಿ ನೆರವನ್ನು ಭಾರತ ಒದಗಿಸುತ್ತಿದೆ. ಈಗಾಗಲೇ ಟರ್ಕಿಗೆ ಭಾರತದಿಂದ ನಾಲ್ಕು ಮಿಲಿಟರಿ ವಿಮಾನಗಳು ಹೋಗಿವೆ. ಆದರೆ ಟರ್ಕಿಗೆ ಹೋಗುತ್ತಿದ್ದ ಭಾರತೀಯ ವಿಮಾನಗಳನ್ನು ಪಾಕಿಸ್ತಾನ ತಡೆದಿವೆ ಎನ್ನುವಂತಹ ಸುದ್ದಿಗಳು ನಿನ್ನೆ ಮಂಗಳವಾರ ಸೋಷಿಯಲ್ ಮೀಡಿಯಾಗಳಲ್ಲಿ (Social Media) ವೈರಲ್ ಆಗಿದ್ದವು. ಟರ್ಕಿಗೆ ಅದರ ಮಿತ್ರದೇಶವೇ ಅಡ್ಡಿಪಡಿಸುತ್ತಿದೆ ಎನ್ನುವಂತಹ ವಿಮರ್ಶೆಗಳು ವ್ಯಕ್ತವಾಗಿದ್ದವು.',\n",
       " '8 கோடி மக்களும் வாழ்த்த வேண்டும்.. எல்லோரும் சேர்ந்து செயல்படுவோம்..முதல்வர் ஸ்டாலின் அழைப்பு']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# direct web link to indian text file was not there so i made github folder containing files\n",
    "urls=[\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/bangla_1_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/bangla_2_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/bangla_3_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/hindi_1_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/hindi_2_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/hindi_3_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/kannada_1_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/kannada_2_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/kannada_3_.txt\",\n",
    "    \"https://raw.githubusercontent.com/7abhisheknn/temp/main/indian_text/tamil_1_.txt\",\n",
    "      ]\n",
    "l=[]\n",
    "for url in urls:\n",
    "    textPage = urlopen(url)\n",
    "    l.append(textPage.read().decode('utf-8'))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the data is indian we cannot apply all preprocessing steps\n",
    "\n",
    "def preprocess_indian_text(corpus):\n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        doc = remove_numbers(doc)\n",
    "        doc = remove_punctuation(doc)\n",
    "        doc = remove_whitespace(doc)\n",
    "        doc = remove_extra_newlines(doc)\n",
    "        normalized_corpus.append(doc)\n",
    "    return normalized_corpus\n",
    "\n",
    "preprocessed_text=preprocess_indian_text(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['গত বছর অক্টোবরে হাওড়ার অপ্রকাশ মুখার্জি লেনের বাসিন্দা ব্যবসায়ী শৈলে পাণ্ডের বাড়িতে হানা দেয় পুলিশ। দু’দিনের অভিযানে নগদ কোটি লক্ষ টাকাসহ উদ্ধার হয় সোনা ও হিরের গয়না।',\n",
       " 'নাগপুরে অস্ট্রেলিয়ার বিরুদ্ধে টেস্ট শুরুর আগেই বিতর্কে ভারতীয় ক্রিকেট। রাহুল দ্রাবিড় থাকার পরেও সূর্যকুমারকে অভিষেকের টুপি দেন রবি শাস্ত্রী। এই ঘটনা নিয়েই প্রশ্ন উঠছে।',\n",
       " 'রত্নগিরির পেট্রো রসায়নের অন্দরের খবর এবং এই প্রকল্প ঘিরে যে দুষ্টচক্র গড়ে উঠেছে তা নিয়ে সোমবার সংবাদপত্রে লিখেছিলেন শশীকান্ত। তার পরই মঙ্গলবার গাড়িচাপা দিয়ে খুন করা হয়।',\n",
       " 'महाविनाश के बीच तुर्की में भूकंप टैक्स पर आक्रोश हजारों की मौत के बाद फूटा लोगों का गुस्सा',\n",
       " 'राहुल के मिनट Vs पीएम मोदी के मिनट किसके भाषण में कौन से मुद्दे रहे हावी',\n",
       " 'बॉर्डरगावस्कर ट्रॉफी कल सेपहला मुकाबला नागपुर मेंइंडिया के टॉप ऑर्डर और स्पिनर्स का रोल अहम वे फैक्टर जो सीरीज का रिजल्ट तय करेंगे',\n",
       " 'ರಾಮಕೃಷ್ಣ ಹೆಗಡೆಯವರಿಗೆ ಕಲ್ಲು ಹೊಡೆದವರು ಯಾರು ರಕ್ತದಲ್ಲೇ ಬ್ರಾಹ್ಮಣ ವಿರೋಧಿತನ ಇದೆ ಜಿಲ್ಲೆ ಇಟ್ಟುಕೊಂಡು ಸಿಎಂ ಆಗುವ ಕನಸೇತಕೆ',\n",
       " 'ಜನವರಿಯಲ್ಲಿ ಟಾಟಾ ಮೋಟಾರ್ಸ್ ಕಾರುಗಳನ್ನು ಮಾರಾಟ ಮಾಡಿದೆ ವಾರ್ಷಿಕ ಆಧಾರದ ಮೇಲೆ ನೋಡುವುದಾದರೆ ಕಾರಿನ ಮಾರಾಟ ಪ್ರತಿಶತದಷ್ಟು ಹೆಚ್ಚಾಗಿದೆ ಕಳೆದ ವರ್ಷ ಈ ಜನವರಿಯಲ್ಲಿ ಕೇವಲ ಯೂನಿಟ್\\u200cಗಳಷ್ಟು ಟಾಟಾ ಕಾರು ಮಾರಾಟವಾಗಿತ್ತು ಆದರೆ ಜನವರಿ ರಲ್ಲಿ ಕಂಪನಿಯು ಇದಕ್ಕಿಂತ ಹೆಚ್ಚು ಯುನಿಟ್\\u200cಗಳನ್ನು ಕಂಪನಿ ಮಾರಾಟ ಮಾಡಿದೆ ಇದರೊಂದಿಗೆ ಟಾಟಾ ಮೋಟಾರ್ಸ್ ದೇಶದ ಮೂರನೇ ಅತಿದೊಡ್ಡ ಕಾರು ಮಾರಾಟ ಕಂಪನಿಯಾಗಿ ಹೊರ ಹೊಮ್ಮಿದೆ ಕಂಪನಿಯ ಹೆಚ್ಚು ಮಾರಾಟವಾಗುವ ಕಾರುಗಳು ಯಾವುವು ನೋಡೋಣ',\n",
       " 'ನವದೆಹಲಿ ಭೂಕಂಪದಿಂದ ಜರ್ಝರಿತವಾಗಿರುವ ಟರ್ಕಿ ಮತ್ತು ಸಿರಿಯಾ Turkey and Syria Earthquake ದೇಶಗಳಿಗೆ ಜಗತ್ತಿನ ಅನೇಕ ದೇಶಗಳು ಸಹಾಯಹಸ್ತ ಚಾಚಿವೆ ಭಾರತ ಕೂಡ ವಿವಿಧ ರಕ್ಷಣಾ ಸಾಮಗ್ರಿಗಳನ್ನು India Rescue Team To Turkey ಟರ್ಕಿಗೆ ಕಳುಹಿಸಿಕೊಟ್ಟಿದೆ ಔಷಧಿ ರಕ್ಷಣಾ ಸಿಬ್ಬಂದಿ ಶ್ವಾನ ದಳ ಇತ್ಯಾದಿ ನೆರವನ್ನು ಭಾರತ ಒದಗಿಸುತ್ತಿದೆ ಈಗಾಗಲೇ ಟರ್ಕಿಗೆ ಭಾರತದಿಂದ ನಾಲ್ಕು ಮಿಲಿಟರಿ ವಿಮಾನಗಳು ಹೋಗಿವೆ ಆದರೆ ಟರ್ಕಿಗೆ ಹೋಗುತ್ತಿದ್ದ ಭಾರತೀಯ ವಿಮಾನಗಳನ್ನು ಪಾಕಿಸ್ತಾನ ತಡೆದಿವೆ ಎನ್ನುವಂತಹ ಸುದ್ದಿಗಳು ನಿನ್ನೆ ಮಂಗಳವಾರ ಸೋಷಿಯಲ್ ಮೀಡಿಯಾಗಳಲ್ಲಿ Social Media ವೈರಲ್ ಆಗಿದ್ದವು ಟರ್ಕಿಗೆ ಅದರ ಮಿತ್ರದೇಶವೇ ಅಡ್ಡಿಪಡಿಸುತ್ತಿದೆ ಎನ್ನುವಂತಹ ವಿಮರ್ಶೆಗಳು ವ್ಯಕ್ತವಾಗಿದ್ದವು',\n",
       " 'கோடி மக்களும் வாழ்த்த வேண்டும் எல்லோரும் சேர்ந்து செயல்படுவோம்முதல்வர் ஸ்டாலின் அழைப்பு']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'গত': {0},\n",
       " 'বছর': {0},\n",
       " 'অক্টোবরে': {0},\n",
       " 'হাওড়ার': {0},\n",
       " 'অপ্রকাশ': {0},\n",
       " 'মুখার্জি': {0},\n",
       " 'লেনের': {0},\n",
       " 'বাসিন্দা': {0},\n",
       " 'ব্যবসায়ী': {0},\n",
       " 'শৈলে': {0},\n",
       " 'পাণ্ডের': {0},\n",
       " 'বাড়িতে': {0},\n",
       " 'হানা': {0},\n",
       " 'দেয়': {0},\n",
       " 'পুলিশ।': {0},\n",
       " 'দু’দিনের': {0},\n",
       " 'অভিযানে': {0},\n",
       " 'নগদ': {0},\n",
       " 'কোটি': {0},\n",
       " 'লক্ষ': {0},\n",
       " 'টাকাসহ': {0},\n",
       " 'উদ্ধার': {0},\n",
       " 'হয়': {0},\n",
       " 'সোনা': {0},\n",
       " 'ও': {0},\n",
       " 'হিরের': {0},\n",
       " 'গয়না।': {0},\n",
       " 'নাগপুরে': {1},\n",
       " 'অস্ট্রেলিয়ার': {1},\n",
       " 'বিরুদ্ধে': {1},\n",
       " 'টেস্ট': {1},\n",
       " 'শুরুর': {1},\n",
       " 'আগেই': {1},\n",
       " 'বিতর্কে': {1},\n",
       " 'ভারতীয়': {1},\n",
       " 'ক্রিকেট।': {1},\n",
       " 'রাহুল': {1},\n",
       " 'দ্রাবিড়': {1},\n",
       " 'থাকার': {1},\n",
       " 'পরেও': {1},\n",
       " 'সূর্যকুমারকে': {1},\n",
       " 'অভিষেকের': {1},\n",
       " 'টুপি': {1},\n",
       " 'দেন': {1},\n",
       " 'রবি': {1},\n",
       " 'শাস্ত্রী।': {1},\n",
       " 'এই': {1, 2},\n",
       " 'ঘটনা': {1},\n",
       " 'নিয়েই': {1},\n",
       " 'প্রশ্ন': {1},\n",
       " 'উঠছে।': {1},\n",
       " 'রত্নগিরির': {2},\n",
       " 'পেট্রো': {2},\n",
       " 'রসায়নের': {2},\n",
       " 'অন্দরের': {2},\n",
       " 'খবর': {2},\n",
       " 'এবং': {2},\n",
       " 'প্রকল্প': {2},\n",
       " 'ঘিরে': {2},\n",
       " 'যে': {2},\n",
       " 'দুষ্টচক্র': {2},\n",
       " 'গড়ে': {2},\n",
       " 'উঠেছে': {2},\n",
       " 'তা': {2},\n",
       " 'নিয়ে': {2},\n",
       " 'সোমবার': {2},\n",
       " 'সংবাদপত্রে': {2},\n",
       " 'লিখেছিলেন': {2},\n",
       " 'শশীকান্ত।': {2},\n",
       " 'তার': {2},\n",
       " 'পরই': {2},\n",
       " 'মঙ্গলবার': {2},\n",
       " 'গাড়িচাপা': {2},\n",
       " 'দিয়ে': {2},\n",
       " 'খুন': {2},\n",
       " 'করা': {2},\n",
       " 'হয়।': {2},\n",
       " 'महाविनाश': {3},\n",
       " 'के': {3, 4, 5},\n",
       " 'बीच': {3},\n",
       " 'तुर्की': {3},\n",
       " 'में': {3, 4},\n",
       " 'भूकंप': {3},\n",
       " 'टैक्स': {3},\n",
       " 'पर': {3},\n",
       " 'आक्रोश': {3},\n",
       " 'हजारों': {3},\n",
       " 'की': {3},\n",
       " 'मौत': {3},\n",
       " 'बाद': {3},\n",
       " 'फूटा': {3},\n",
       " 'लोगों': {3},\n",
       " 'का': {3, 5},\n",
       " 'गुस्सा': {3},\n",
       " 'राहुल': {4},\n",
       " 'मिनट': {4},\n",
       " 'Vs': {4},\n",
       " 'पीएम': {4},\n",
       " 'मोदी': {4},\n",
       " 'किसके': {4},\n",
       " 'भाषण': {4},\n",
       " 'कौन': {4},\n",
       " 'से': {4},\n",
       " 'मुद्दे': {4},\n",
       " 'रहे': {4},\n",
       " 'हावी': {4},\n",
       " 'बॉर्डरगावस्कर': {5},\n",
       " 'ट्रॉफी': {5},\n",
       " 'कल': {5},\n",
       " 'सेपहला': {5},\n",
       " 'मुकाबला': {5},\n",
       " 'नागपुर': {5},\n",
       " 'मेंइंडिया': {5},\n",
       " 'टॉप': {5},\n",
       " 'ऑर्डर': {5},\n",
       " 'और': {5},\n",
       " 'स्पिनर्स': {5},\n",
       " 'रोल': {5},\n",
       " 'अहम': {5},\n",
       " 'वे': {5},\n",
       " 'फैक्टर': {5},\n",
       " 'जो': {5},\n",
       " 'सीरीज': {5},\n",
       " 'रिजल्ट': {5},\n",
       " 'तय': {5},\n",
       " 'करेंगे': {5},\n",
       " 'ರಾಮಕೃಷ್ಣ': {6},\n",
       " 'ಹೆಗಡೆಯವರಿಗೆ': {6},\n",
       " 'ಕಲ್ಲು': {6},\n",
       " 'ಹೊಡೆದವರು': {6},\n",
       " 'ಯಾರು': {6},\n",
       " 'ರಕ್ತದಲ್ಲೇ': {6},\n",
       " 'ಬ್ರಾಹ್ಮಣ': {6},\n",
       " 'ವಿರೋಧಿತನ': {6},\n",
       " 'ಇದೆ': {6},\n",
       " 'ಜಿಲ್ಲೆ': {6},\n",
       " 'ಇಟ್ಟುಕೊಂಡು': {6},\n",
       " 'ಸಿಎಂ': {6},\n",
       " 'ಆಗುವ': {6},\n",
       " 'ಕನಸೇತಕೆ': {6},\n",
       " 'ಜನವರಿಯಲ್ಲಿ': {7},\n",
       " 'ಟಾಟಾ': {7},\n",
       " 'ಮೋಟಾರ್ಸ್': {7},\n",
       " 'ಕಾರುಗಳನ್ನು': {7},\n",
       " 'ಮಾರಾಟ': {7},\n",
       " 'ಮಾಡಿದೆ': {7},\n",
       " 'ವಾರ್ಷಿಕ': {7},\n",
       " 'ಆಧಾರದ': {7},\n",
       " 'ಮೇಲೆ': {7},\n",
       " 'ನೋಡುವುದಾದರೆ': {7},\n",
       " 'ಕಾರಿನ': {7},\n",
       " 'ಪ್ರತಿಶತದಷ್ಟು': {7},\n",
       " 'ಹೆಚ್ಚಾಗಿದೆ': {7},\n",
       " 'ಕಳೆದ': {7},\n",
       " 'ವರ್ಷ': {7},\n",
       " 'ಈ': {7},\n",
       " 'ಕೇವಲ': {7},\n",
       " 'ಯೂನಿಟ್\\u200cಗಳಷ್ಟು': {7},\n",
       " 'ಕಾರು': {7},\n",
       " 'ಮಾರಾಟವಾಗಿತ್ತು': {7},\n",
       " 'ಆದರೆ': {7, 8},\n",
       " 'ಜನವರಿ': {7},\n",
       " 'ರಲ್ಲಿ': {7},\n",
       " 'ಕಂಪನಿಯು': {7},\n",
       " 'ಇದಕ್ಕಿಂತ': {7},\n",
       " 'ಹೆಚ್ಚು': {7},\n",
       " 'ಯುನಿಟ್\\u200cಗಳನ್ನು': {7},\n",
       " 'ಕಂಪನಿ': {7},\n",
       " 'ಇದರೊಂದಿಗೆ': {7},\n",
       " 'ದೇಶದ': {7},\n",
       " 'ಮೂರನೇ': {7},\n",
       " 'ಅತಿದೊಡ್ಡ': {7},\n",
       " 'ಕಂಪನಿಯಾಗಿ': {7},\n",
       " 'ಹೊರ': {7},\n",
       " 'ಹೊಮ್ಮಿದೆ': {7},\n",
       " 'ಕಂಪನಿಯ': {7},\n",
       " 'ಮಾರಾಟವಾಗುವ': {7},\n",
       " 'ಕಾರುಗಳು': {7},\n",
       " 'ಯಾವುವು': {7},\n",
       " 'ನೋಡೋಣ': {7},\n",
       " 'ನವದೆಹಲಿ': {8},\n",
       " 'ಭೂಕಂಪದಿಂದ': {8},\n",
       " 'ಜರ್ಝರಿತವಾಗಿರುವ': {8},\n",
       " 'ಟರ್ಕಿ': {8},\n",
       " 'ಮತ್ತು': {8},\n",
       " 'ಸಿರಿಯಾ': {8},\n",
       " 'Turkey': {8},\n",
       " 'and': {8},\n",
       " 'Syria': {8},\n",
       " 'Earthquake': {8},\n",
       " 'ದೇಶಗಳಿಗೆ': {8},\n",
       " 'ಜಗತ್ತಿನ': {8},\n",
       " 'ಅನೇಕ': {8},\n",
       " 'ದೇಶಗಳು': {8},\n",
       " 'ಸಹಾಯಹಸ್ತ': {8},\n",
       " 'ಚಾಚಿವೆ': {8},\n",
       " 'ಭಾರತ': {8},\n",
       " 'ಕೂಡ': {8},\n",
       " 'ವಿವಿಧ': {8},\n",
       " 'ರಕ್ಷಣಾ': {8},\n",
       " 'ಸಾಮಗ್ರಿಗಳನ್ನು': {8},\n",
       " 'India': {8},\n",
       " 'Rescue': {8},\n",
       " 'Team': {8},\n",
       " 'To': {8},\n",
       " 'ಟರ್ಕಿಗೆ': {8},\n",
       " 'ಕಳುಹಿಸಿಕೊಟ್ಟಿದೆ': {8},\n",
       " 'ಔಷಧಿ': {8},\n",
       " 'ಸಿಬ್ಬಂದಿ': {8},\n",
       " 'ಶ್ವಾನ': {8},\n",
       " 'ದಳ': {8},\n",
       " 'ಇತ್ಯಾದಿ': {8},\n",
       " 'ನೆರವನ್ನು': {8},\n",
       " 'ಒದಗಿಸುತ್ತಿದೆ': {8},\n",
       " 'ಈಗಾಗಲೇ': {8},\n",
       " 'ಭಾರತದಿಂದ': {8},\n",
       " 'ನಾಲ್ಕು': {8},\n",
       " 'ಮಿಲಿಟರಿ': {8},\n",
       " 'ವಿಮಾನಗಳು': {8},\n",
       " 'ಹೋಗಿವೆ': {8},\n",
       " 'ಹೋಗುತ್ತಿದ್ದ': {8},\n",
       " 'ಭಾರತೀಯ': {8},\n",
       " 'ವಿಮಾನಗಳನ್ನು': {8},\n",
       " 'ಪಾಕಿಸ್ತಾನ': {8},\n",
       " 'ತಡೆದಿವೆ': {8},\n",
       " 'ಎನ್ನುವಂತಹ': {8},\n",
       " 'ಸುದ್ದಿಗಳು': {8},\n",
       " 'ನಿನ್ನೆ': {8},\n",
       " 'ಮಂಗಳವಾರ': {8},\n",
       " 'ಸೋಷಿಯಲ್': {8},\n",
       " 'ಮೀಡಿಯಾಗಳಲ್ಲಿ': {8},\n",
       " 'Social': {8},\n",
       " 'Media': {8},\n",
       " 'ವೈರಲ್': {8},\n",
       " 'ಆಗಿದ್ದವು': {8},\n",
       " 'ಅದರ': {8},\n",
       " 'ಮಿತ್ರದೇಶವೇ': {8},\n",
       " 'ಅಡ್ಡಿಪಡಿಸುತ್ತಿದೆ': {8},\n",
       " 'ವಿಮರ್ಶೆಗಳು': {8},\n",
       " 'ವ್ಯಕ್ತವಾಗಿದ್ದವು': {8},\n",
       " 'கோடி': {9},\n",
       " 'மக்களும்': {9},\n",
       " 'வாழ்த்த': {9},\n",
       " 'வேண்டும்': {9},\n",
       " 'எல்லோரும்': {9},\n",
       " 'சேர்ந்து': {9},\n",
       " 'செயல்படுவோம்முதல்வர்': {9},\n",
       " 'ஸ்டாலின்': {9},\n",
       " 'அழைப்பு': {9}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateInvertedIndexDict(preprocessed_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Shah Rukh Khan\\xe2\\x80\\x99s Pathaan continues to demolish records at the box office. Directed by Siddharth Anand, the spy thriller, also featuring John Abraham and Deepika Padukone, has boosted Bollywood\\xe2\\x80\\x99s flailing confidence after a rough 2022. Pathaan is going strong in its second week, and is expected to have earned around Rs 6.7 crore on day 15 of release, according to the industry tracker Sacnilk. This brings the total domestic collection of the film to Rs 452.9 crore nett approximately. The film even managed to pass the second Monday test with flying colours, earning Rs 15.7 crore, and earned Rs 7.75 crore on Tuesday. Pathaan has already broken KGF: Chapter 2\\xe2\\x80\\x99s record of Rs 434 crore in the Hindi market.',\n",
       " b'For Bharat, who was a ball boy in 2005, when MS Dhoni announced himself on the international stage by hammering a hapless Pakistan for 148 at Visakhapatnam, it was a dream come true.\\n',\n",
       " b'2023 is the year where \\xe2\\x80\\x9cArtificial Intelligence\\xe2\\x80\\x9d or AI has dominated the discourse. Much of this has been dominated by OpenAI\\xe2\\x80\\x99s ChatGPT, the chatbot which has gone viral since it launched in November last year, and already has over 100 million users. Microsoft has also gone all in on AI and invested $10 billion in OpenAI along with announcing a new version of Bing which will be integrated with the start-up\\xe2\\x80\\x99s AI technology. In response to this Google has also announced its own chatbot called Bard, which has had a rough start thanks to one incorrect answer. Let\\xe2\\x80\\x99s take a look at key developments in AI news in the past few weeks.',\n",
       " b'Between 2014 and 2018, over 60% of IIT-Bombay graduates took up jobs in sectors not related to their branches of study, a trend seen across all disciplines except Computer Science and\\xc2\\xa0 Engineering (CSE) and Electrical Engineering (EE), according to a study by a group of researchers from the Centre for Policy Studies, IIT-Bombay.',\n",
       " b'The reason the RBI has stuck to the hawkish stance could lie in its outlook for India\\xe2\\x80\\x99s economic growth and inflation in 2023-24. The central bank expects the GDP to grow by 6.4%, but the growth rate to slow in every successive quarter through the year; and for retail inflation to not fall below 5% in any quarter.',\n",
       " b'Under the protocol, Northern Ireland remains in the EU single market, and trade-and-customs inspections of goods coming from Great Britain take place at its ports along the Irish Sea.',\n",
       " b\"According to Congress sources, Singh's office asked the party to change his seat as it was difficult for him to walk to the front row. The party then arranged for him to be seated in the back row, near the aisle.\",\n",
       " b\"Replying to the Motion of Thanks to the President's Address in Rajya Sabha, Prime Minister Narendra\\nModi Thursday hit out at the Congress government and said former Prime Minister Indira Gandhi used\\nArticle 356 of the Constitution 50 times to dismiss elected state governments.\\n\\n\\x0c\",\n",
       " b'Turkey Earthquake News Live Updates, February 09: Rescue efforts continued on Thursday as the\\ndeath toll crossed 16,000, but hopes of finding survivors diminished on the fourth day of rescue workers.\\nAs per experts, though people can survive in the rubble for a week, the first 72 hours of the earthquake are\\ncritical.\\n\\n\\x0c',\n",
       " b'People above 14 years of age need to consume 2.4\\nmicrograms (mcg) every day. However, the requirement\\nchanges with the calorie our body needs at a particular time.\\nFor instance, a pregnant woman needs to ensure an intake of\\n2.6 mcg, and a lactating woman 2.8 mcg daily, says Dr\\nSuranjit Chatterjee, Senior Consultant , Internal Medicine,\\nIndraprastha Apollo Hospital, New Delhi\\n\\n\\x0c']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/1.odt\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/2.odt\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/3.odt\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/4.odt\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/1.docx\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/2.docx\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/3.docx\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/1.pdf\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/2.pdf\",\n",
    "    \"https://github.com/7abhisheknn/temp/raw/main/different_format_documents/3.pdf\",\n",
    "      ]\n",
    "l=[]\n",
    "for url in urls:\n",
    "  response = requests.get(url)\n",
    "\n",
    "  saveFile=\"\"\n",
    "  if (url[-3:]==\"odt\"):\n",
    "    saveFile=\"temp.odt\"\n",
    "  elif (url[-3:]==\"ocx\"):\n",
    "    saveFile=\"temp.docx\"\n",
    "  else:\n",
    "    saveFile=\"temp.pdf\"\n",
    "\n",
    "  open(saveFile, \"wb\").write(response.content)\n",
    "  text = textract.process(saveFile)\n",
    "  l.append(text)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bshah rukh khanxexx pathaan continu demolish record box offic direct siddharth anand spi thriller also featur john abraham deepika padukon ha boost bollywoodxexx flail confid rough pathaan go strong second week expect earn around r crore day releas accord industri tracker sacnilk thi bring total domest collect film r crore nett approxim film even manag pa second monday test fli colour earn r crore earn r crore tuesday pathaan ha alreadi broken kgf chapter xexx record r crore hindi market',\n",
       " 'bfor bharat wa ball boy dhoni announc intern stage hammer hapless pakistan visakhapatnam wa dream come truen',\n",
       " 'b year xexxcartifici intelligencexexxd ai ha domin discours much thi ha domin openaixexx chatgpt chatbot ha gone viral sinc launch novemb last year alreadi ha million user microsoft ha also gone ai invest billion openai along announc new version bing integr startupxexx ai technolog respons thi googl ha also announc chatbot call bard ha rough start thank one incorrect answer letxexx take look key develop ai news past week',\n",
       " 'bbetween iitbombay graduat took job sector relat branch studi trend seen across disciplin except comput scienc andxcxa engin cse electr engin ee accord studi group research centr polici studi iitbombay',\n",
       " 'bthe reason rbi ha stuck hawkish stanc could lie outlook indiaxexx econom growth inflat central bank expect gdp grow growth rate slow everi success quarter year retail inflat fall ani quarter',\n",
       " 'bunder protocol northern ireland remain eu singl market tradeandcustom inspect good come great britain take place port along irish sea',\n",
       " 'baccord congress sourc singh offic ask parti chang hi seat wa difficult walk front row parti arrang seat back row near aisl',\n",
       " 'brepli motion thank presid address rajya sabha prime minist narendranmodi thursday hit congress govern said former prime minist indira gandhi usednarticl constitut time dismiss elect state governmentsnnxc',\n",
       " 'bturkey earthquak news live updat februari rescu effort continu thursday thendeath toll cross hope find survivor diminish fourth day rescu workersna per expert though peopl surviv rubbl week first hour earthquak arencriticalnnxc',\n",
       " 'bpeopl abov year age need consum nmicrogram mcg everi day howev requirementnchang calori bodi need particular timenfor instanc pregnant woman need ensur intak ofn mcg lactat woman mcg daili say drnsuranjit chatterje senior consult intern medicinenindraprastha apollo hospit new delhinnxc']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(l)):\n",
    "    l[i]=str(l[i])\n",
    "preprocessed_text=preprocess(l)\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bshah': {0},\n",
       " 'rukh': {0},\n",
       " 'khanxexx': {0},\n",
       " 'pathaan': {0},\n",
       " 'continu': {0, 8},\n",
       " 'demolish': {0},\n",
       " 'record': {0},\n",
       " 'box': {0},\n",
       " 'offic': {0, 6},\n",
       " 'direct': {0},\n",
       " 'siddharth': {0},\n",
       " 'anand': {0},\n",
       " 'spi': {0},\n",
       " 'thriller': {0},\n",
       " 'also': {0, 2},\n",
       " 'featur': {0},\n",
       " 'john': {0},\n",
       " 'abraham': {0},\n",
       " 'deepika': {0},\n",
       " 'padukon': {0},\n",
       " 'ha': {0, 2, 4},\n",
       " 'boost': {0},\n",
       " 'bollywoodxexx': {0},\n",
       " 'flail': {0},\n",
       " 'confid': {0},\n",
       " 'rough': {0, 2},\n",
       " 'go': {0},\n",
       " 'strong': {0},\n",
       " 'second': {0},\n",
       " 'week': {0, 2, 8},\n",
       " 'expect': {0, 4},\n",
       " 'earn': {0},\n",
       " 'around': {0},\n",
       " 'r': {0},\n",
       " 'crore': {0},\n",
       " 'day': {0, 8, 9},\n",
       " 'releas': {0},\n",
       " 'accord': {0, 3},\n",
       " 'industri': {0},\n",
       " 'tracker': {0},\n",
       " 'sacnilk': {0},\n",
       " 'thi': {0, 2},\n",
       " 'bring': {0},\n",
       " 'total': {0},\n",
       " 'domest': {0},\n",
       " 'collect': {0},\n",
       " 'film': {0},\n",
       " 'nett': {0},\n",
       " 'approxim': {0},\n",
       " 'even': {0},\n",
       " 'manag': {0},\n",
       " 'pa': {0},\n",
       " 'monday': {0},\n",
       " 'test': {0},\n",
       " 'fli': {0},\n",
       " 'colour': {0},\n",
       " 'tuesday': {0},\n",
       " 'alreadi': {0, 2},\n",
       " 'broken': {0},\n",
       " 'kgf': {0},\n",
       " 'chapter': {0},\n",
       " 'xexx': {0},\n",
       " 'hindi': {0},\n",
       " 'market': {0, 5},\n",
       " 'bfor': {1},\n",
       " 'bharat': {1},\n",
       " 'wa': {1, 6},\n",
       " 'ball': {1},\n",
       " 'boy': {1},\n",
       " 'dhoni': {1},\n",
       " 'announc': {1, 2},\n",
       " 'intern': {1, 9},\n",
       " 'stage': {1},\n",
       " 'hammer': {1},\n",
       " 'hapless': {1},\n",
       " 'pakistan': {1},\n",
       " 'visakhapatnam': {1},\n",
       " 'dream': {1},\n",
       " 'come': {1, 5},\n",
       " 'truen': {1},\n",
       " 'b': {2},\n",
       " 'year': {2, 4, 9},\n",
       " 'xexxcartifici': {2},\n",
       " 'intelligencexexxd': {2},\n",
       " 'ai': {2},\n",
       " 'domin': {2},\n",
       " 'discours': {2},\n",
       " 'much': {2},\n",
       " 'openaixexx': {2},\n",
       " 'chatgpt': {2},\n",
       " 'chatbot': {2},\n",
       " 'gone': {2},\n",
       " 'viral': {2},\n",
       " 'sinc': {2},\n",
       " 'launch': {2},\n",
       " 'novemb': {2},\n",
       " 'last': {2},\n",
       " 'million': {2},\n",
       " 'user': {2},\n",
       " 'microsoft': {2},\n",
       " 'invest': {2},\n",
       " 'billion': {2},\n",
       " 'openai': {2},\n",
       " 'along': {2, 5},\n",
       " 'new': {2, 9},\n",
       " 'version': {2},\n",
       " 'bing': {2},\n",
       " 'integr': {2},\n",
       " 'startupxexx': {2},\n",
       " 'technolog': {2},\n",
       " 'respons': {2},\n",
       " 'googl': {2},\n",
       " 'call': {2},\n",
       " 'bard': {2},\n",
       " 'start': {2},\n",
       " 'thank': {2, 7},\n",
       " 'one': {2},\n",
       " 'incorrect': {2},\n",
       " 'answer': {2},\n",
       " 'letxexx': {2},\n",
       " 'take': {2, 5},\n",
       " 'look': {2},\n",
       " 'key': {2},\n",
       " 'develop': {2},\n",
       " 'news': {2, 8},\n",
       " 'past': {2},\n",
       " 'bbetween': {3},\n",
       " 'iitbombay': {3},\n",
       " 'graduat': {3},\n",
       " 'took': {3},\n",
       " 'job': {3},\n",
       " 'sector': {3},\n",
       " 'relat': {3},\n",
       " 'branch': {3},\n",
       " 'studi': {3},\n",
       " 'trend': {3},\n",
       " 'seen': {3},\n",
       " 'across': {3},\n",
       " 'disciplin': {3},\n",
       " 'except': {3},\n",
       " 'comput': {3},\n",
       " 'scienc': {3},\n",
       " 'andxcxa': {3},\n",
       " 'engin': {3},\n",
       " 'cse': {3},\n",
       " 'electr': {3},\n",
       " 'ee': {3},\n",
       " 'group': {3},\n",
       " 'research': {3},\n",
       " 'centr': {3},\n",
       " 'polici': {3},\n",
       " 'bthe': {4},\n",
       " 'reason': {4},\n",
       " 'rbi': {4},\n",
       " 'stuck': {4},\n",
       " 'hawkish': {4},\n",
       " 'stanc': {4},\n",
       " 'could': {4},\n",
       " 'lie': {4},\n",
       " 'outlook': {4},\n",
       " 'indiaxexx': {4},\n",
       " 'econom': {4},\n",
       " 'growth': {4},\n",
       " 'inflat': {4},\n",
       " 'central': {4},\n",
       " 'bank': {4},\n",
       " 'gdp': {4},\n",
       " 'grow': {4},\n",
       " 'rate': {4},\n",
       " 'slow': {4},\n",
       " 'everi': {4, 9},\n",
       " 'success': {4},\n",
       " 'quarter': {4},\n",
       " 'retail': {4},\n",
       " 'fall': {4},\n",
       " 'ani': {4},\n",
       " 'bunder': {5},\n",
       " 'protocol': {5},\n",
       " 'northern': {5},\n",
       " 'ireland': {5},\n",
       " 'remain': {5},\n",
       " 'eu': {5},\n",
       " 'singl': {5},\n",
       " 'tradeandcustom': {5},\n",
       " 'inspect': {5},\n",
       " 'good': {5},\n",
       " 'great': {5},\n",
       " 'britain': {5},\n",
       " 'place': {5},\n",
       " 'port': {5},\n",
       " 'irish': {5},\n",
       " 'sea': {5},\n",
       " 'baccord': {6},\n",
       " 'congress': {6, 7},\n",
       " 'sourc': {6},\n",
       " 'singh': {6},\n",
       " 'ask': {6},\n",
       " 'parti': {6},\n",
       " 'chang': {6},\n",
       " 'hi': {6},\n",
       " 'seat': {6},\n",
       " 'difficult': {6},\n",
       " 'walk': {6},\n",
       " 'front': {6},\n",
       " 'row': {6},\n",
       " 'arrang': {6},\n",
       " 'back': {6},\n",
       " 'near': {6},\n",
       " 'aisl': {6},\n",
       " 'brepli': {7},\n",
       " 'motion': {7},\n",
       " 'presid': {7},\n",
       " 'address': {7},\n",
       " 'rajya': {7},\n",
       " 'sabha': {7},\n",
       " 'prime': {7},\n",
       " 'minist': {7},\n",
       " 'narendranmodi': {7},\n",
       " 'thursday': {7, 8},\n",
       " 'hit': {7},\n",
       " 'govern': {7},\n",
       " 'said': {7},\n",
       " 'former': {7},\n",
       " 'indira': {7},\n",
       " 'gandhi': {7},\n",
       " 'usednarticl': {7},\n",
       " 'constitut': {7},\n",
       " 'time': {7},\n",
       " 'dismiss': {7},\n",
       " 'elect': {7},\n",
       " 'state': {7},\n",
       " 'governmentsnnxc': {7},\n",
       " 'bturkey': {8},\n",
       " 'earthquak': {8},\n",
       " 'live': {8},\n",
       " 'updat': {8},\n",
       " 'februari': {8},\n",
       " 'rescu': {8},\n",
       " 'effort': {8},\n",
       " 'thendeath': {8},\n",
       " 'toll': {8},\n",
       " 'cross': {8},\n",
       " 'hope': {8},\n",
       " 'find': {8},\n",
       " 'survivor': {8},\n",
       " 'diminish': {8},\n",
       " 'fourth': {8},\n",
       " 'workersna': {8},\n",
       " 'per': {8},\n",
       " 'expert': {8},\n",
       " 'though': {8},\n",
       " 'peopl': {8},\n",
       " 'surviv': {8},\n",
       " 'rubbl': {8},\n",
       " 'first': {8},\n",
       " 'hour': {8},\n",
       " 'arencriticalnnxc': {8},\n",
       " 'bpeopl': {9},\n",
       " 'abov': {9},\n",
       " 'age': {9},\n",
       " 'need': {9},\n",
       " 'consum': {9},\n",
       " 'nmicrogram': {9},\n",
       " 'mcg': {9},\n",
       " 'howev': {9},\n",
       " 'requirementnchang': {9},\n",
       " 'calori': {9},\n",
       " 'bodi': {9},\n",
       " 'particular': {9},\n",
       " 'timenfor': {9},\n",
       " 'instanc': {9},\n",
       " 'pregnant': {9},\n",
       " 'woman': {9},\n",
       " 'ensur': {9},\n",
       " 'intak': {9},\n",
       " 'ofn': {9},\n",
       " 'lactat': {9},\n",
       " 'daili': {9},\n",
       " 'say': {9},\n",
       " 'drnsuranjit': {9},\n",
       " 'chatterje': {9},\n",
       " 'senior': {9},\n",
       " 'consult': {9},\n",
       " 'medicinenindraprastha': {9},\n",
       " 'apollo': {9},\n",
       " 'hospit': {9},\n",
       " 'delhinnxc': {9}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateInvertedIndexDict(preprocessed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
